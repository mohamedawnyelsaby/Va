# ===========================================
# ROBOTS.TXT - SEO OPTIMIZATION (PRODUCTION)
# ===========================================
# Project: VA Travel
# Framework: Next.js (App Router)
# Platform: Vercel
# ===========================================

# ===========================================
# GLOBAL RULES
# ===========================================

User-agent: *

# Allow crawling by default
Allow: /

# Disallow sensitive / non-public areas
Disallow: /api/
Disallow: /admin/
Disallow: /_next/
Disallow: /auth/
Disallow: /dashboard/
Disallow: /settings/

# IMPORTANT:
# Do NOT block query params.
# Canonical + hreflang handle duplication safely.

# ===========================================
# SITEMAPS
# ===========================================

Sitemap: https://va-pied.vercel.app/sitemap.xml
Sitemap: https://va-pied.vercel.app/sitemap-hotels.xml
Sitemap: https://va-pied.vercel.app/sitemap-cities.xml
Sitemap: https://va-pied.vercel.app/sitemap-attractions.xml

# ===========================================
# MAJOR SEARCH ENGINES
# ===========================================

User-agent: Googlebot
Allow: /
Disallow: /api/
Disallow: /admin/

User-agent: Bingbot
Allow: /
Disallow: /api/
Disallow: /admin/

User-agent: Yandexbot
Allow: /
Disallow: /api/
Disallow: /admin/

User-agent: Baiduspider
Allow: /
Disallow: /api/
Disallow: /admin/

# ===========================================
# BLOCK AGGRESSIVE SCRAPERS
# ===========================================

User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# ===========================================
# AI CRAWLERS (OPTIONAL - CONTENT PROTECTION)
# ===========================================

User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

# ===========================================
# NOTES
# ===========================================
# - File location: /public/robots.txt
# - Test with Google Search Console
# - Update sitemap URLs if domain changes
# - Review rules every 3â€“6 months
# ===========================================
